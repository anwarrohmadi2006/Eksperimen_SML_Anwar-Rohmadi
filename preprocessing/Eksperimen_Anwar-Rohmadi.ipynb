{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.7"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# **EKSPERIMEN MACHINE LEARNING - HOUSE PRICES PREDICTION**\n",
                "\n",
                "**Author:** Anwar Rohmadi  \n",
                "**Dataset:** House Prices - Advanced Regression Techniques (Kaggle)  \n",
                "**Task:** Regression (Prediksi Harga Rumah)  \n",
                "**Date:** 2024\n",
                "\n",
                "---"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **1. Perkenalan Dataset**\n",
                "\n",
                "## 1.1 Sumber Dataset\n",
                "Dataset ini berasal dari kompetisi Kaggle **\"House Prices - Advanced Regression Techniques\"**.\n",
                "\n",
                "**URL:** https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques\n",
                "\n",
                "## 1.2 Deskripsi Dataset\n",
                "Dataset berisi **79 variabel** yang menjelaskan berbagai aspek rumah residensial di Ames, Iowa. Target variabel adalah **SalePrice** (harga jual rumah dalam USD).\n",
                "\n",
                "## 1.3 Karakteristik Dataset\n",
                "| Aspek | Detail |\n",
                "|-------|--------|\n",
                "| Jumlah Sampel (Train) | 1,460 |\n",
                "| Jumlah Sampel (Test) | 1,459 |\n",
                "| Jumlah Fitur | 79 |\n",
                "| Target | SalePrice (Continuous) |\n",
                "| Task Type | Regression |\n",
                "| Missing Values | Ada (beberapa kolom) |\n",
                "| Tipe Data | Numerik + Kategorikal |"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **2. Import Library**"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Data Manipulation\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Preprocessing\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "\n",
                "# Metrics\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
                "\n",
                "# Utilities\n",
                "import os\n",
                "import json\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Settings\n",
                "pd.set_option('display.max_columns', 100)\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "\n",
                "print(\"Libraries imported successfully!\")\n",
                "print(f\"Pandas version: {pd.__version__}\")\n",
                "print(f\"NumPy version: {np.__version__}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **3. Memuat Dataset**"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Konfigurasi\n",
                "RAW_DIR = \"../house_prices_raw\"\n",
                "PROCESSED_DIR = \"../house_prices_preprocessing\"\n",
                "TARGET_COL = \"SalePrice\"\n",
                "ID_COL = \"Id\"\n",
                "\n",
                "# Load dataset\n",
                "train_df = pd.read_csv(f\"{RAW_DIR}/train.csv\")\n",
                "test_df = pd.read_csv(f\"{RAW_DIR}/test.csv\")\n",
                "\n",
                "print(f\"Train dataset shape: {train_df.shape}\")\n",
                "print(f\"Test dataset shape: {test_df.shape}\")\n",
                "print(f\"\\nTarget column: {TARGET_COL}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Preview data\n",
                "train_df.head()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Info dataset\n",
                "train_df.info()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **4. Exploratory Data Analysis (EDA)**\n",
                "\n",
                "## 4.1 Statistik Deskriptif"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Statistik deskriptif numerik\n",
                "train_df.describe()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Statistik target variable\n",
                "print(\"=\" * 50)\n",
                "print(\"STATISTIK TARGET (SalePrice)\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Mean: ${train_df[TARGET_COL].mean():,.2f}\")\n",
                "print(f\"Median: ${train_df[TARGET_COL].median():,.2f}\")\n",
                "print(f\"Std: ${train_df[TARGET_COL].std():,.2f}\")\n",
                "print(f\"Min: ${train_df[TARGET_COL].min():,.2f}\")\n",
                "print(f\"Max: ${train_df[TARGET_COL].max():,.2f}\")\n",
                "print(f\"Skewness: {train_df[TARGET_COL].skew():.4f}\")\n",
                "print(f\"Kurtosis: {train_df[TARGET_COL].kurtosis():.4f}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4.2 Distribusi Target Variable"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Histogram\n",
                "axes[0].hist(train_df[TARGET_COL], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
                "axes[0].set_xlabel('SalePrice ($)')\n",
                "axes[0].set_ylabel('Frequency')\n",
                "axes[0].set_title('Distribution of SalePrice')\n",
                "axes[0].axvline(train_df[TARGET_COL].mean(), color='red', linestyle='--', label=f'Mean: ${train_df[TARGET_COL].mean():,.0f}')\n",
                "axes[0].axvline(train_df[TARGET_COL].median(), color='green', linestyle='--', label=f'Median: ${train_df[TARGET_COL].median():,.0f}')\n",
                "axes[0].legend()\n",
                "\n",
                "# Log-transformed\n",
                "axes[1].hist(np.log1p(train_df[TARGET_COL]), bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
                "axes[1].set_xlabel('Log(SalePrice + 1)')\n",
                "axes[1].set_ylabel('Frequency')\n",
                "axes[1].set_title('Distribution of Log-Transformed SalePrice')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('target_distribution.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nðŸ“Š Insight: Target variable menunjukkan right-skewed distribution.\")\n",
                "print(\"   Log transformation dapat membantu menormalkan distribusi.\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4.3 Analisis Missing Values"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Hitung missing values\n",
                "missing = train_df.isnull().sum()\n",
                "missing_pct = (missing / len(train_df)) * 100\n",
                "missing_df = pd.DataFrame({\n",
                "    'Missing Count': missing,\n",
                "    'Missing %': missing_pct\n",
                "}).sort_values('Missing %', ascending=False)\n",
                "\n",
                "# Filter kolom dengan missing values\n",
                "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
                "\n",
                "print(f\"Jumlah kolom dengan missing values: {len(missing_df)}\")\n",
                "print(\"\\nTop 10 kolom dengan missing values terbanyak:\")\n",
                "missing_df.head(10)"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Visualisasi missing values\n",
                "plt.figure(figsize=(12, 8))\n",
                "top_missing = missing_df.head(15)\n",
                "plt.barh(top_missing.index, top_missing['Missing %'], color='coral')\n",
                "plt.xlabel('Missing Percentage (%)')\n",
                "plt.title('Top 15 Features with Missing Values')\n",
                "plt.gca().invert_yaxis()\n",
                "for i, v in enumerate(top_missing['Missing %']):\n",
                "    plt.text(v + 0.5, i, f'{v:.1f}%', va='center')\n",
                "plt.tight_layout()\n",
                "plt.savefig('missing_values.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4.4 Korelasi Fitur Numerik"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Hitung korelasi dengan target\n",
                "numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
                "correlations = train_df[numeric_cols].corr()[TARGET_COL].drop(TARGET_COL).sort_values(ascending=False)\n",
                "\n",
                "print(\"Top 10 fitur berkorelasi POSITIF dengan SalePrice:\")\n",
                "print(correlations.head(10))\n",
                "print(\"\\nTop 10 fitur berkorelasi NEGATIF dengan SalePrice:\")\n",
                "print(correlations.tail(10))"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Heatmap korelasi top features\n",
                "top_corr_features = correlations.abs().nlargest(15).index.tolist()\n",
                "top_corr_features.append(TARGET_COL)\n",
                "\n",
                "plt.figure(figsize=(12, 10))\n",
                "corr_matrix = train_df[top_corr_features].corr()\n",
                "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
                "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
                "            center=0, square=True, linewidths=0.5)\n",
                "plt.title('Correlation Heatmap - Top 15 Features')\n",
                "plt.tight_layout()\n",
                "plt.savefig('correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4.5 Analisis Fitur Kategorikal"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Identifikasi kolom kategorikal\n",
                "cat_cols = train_df.select_dtypes(include=['object']).columns\n",
                "print(f\"Jumlah fitur kategorikal: {len(cat_cols)}\")\n",
                "print(f\"\\nFitur kategorikal: {list(cat_cols)}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Analisis beberapa fitur kategorikal penting\n",
                "important_cats = ['Neighborhood', 'OverallQual', 'ExterQual', 'KitchenQual']\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, col in enumerate(important_cats):\n",
                "    if col in train_df.columns:\n",
                "        if train_df[col].dtype == 'object':\n",
                "            order = train_df.groupby(col)[TARGET_COL].median().sort_values(ascending=False).index\n",
                "            sns.boxplot(data=train_df, x=col, y=TARGET_COL, order=order, ax=axes[i])\n",
                "        else:\n",
                "            sns.boxplot(data=train_df, x=col, y=TARGET_COL, ax=axes[i])\n",
                "        axes[i].set_title(f'{col} vs SalePrice')\n",
                "        axes[i].tick_params(axis='x', rotation=45)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('categorical_analysis.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4.6 Ringkasan EDA\n",
                "\n",
                "### Key Findings:\n",
                "1. **Target Variable (SalePrice)**: Right-skewed, range $34,900 - $755,000\n",
                "2. **Missing Values**: 19 kolom memiliki missing values, PoolQC (99.5%), MiscFeature (96.3%), Alley (93.8%) tertinggi\n",
                "3. **Top Correlated Features**: OverallQual (0.79), GrLivArea (0.71), GarageCars (0.64)\n",
                "4. **Kategorikal Penting**: Neighborhood, OverallQual, ExterQual berpengaruh signifikan terhadap harga"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **5. Data Preprocessing**\n",
                "\n",
                "## 5.1 Handling Missing Values"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "def handle_missing_values(df):\n",
                "    \"\"\"Handle missing values dalam dataset\"\"\"\n",
                "    df = df.copy()\n",
                "    \n",
                "    # Numeric: fill with median\n",
                "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
                "    for col in numeric_cols:\n",
                "        if df[col].isnull().sum() > 0:\n",
                "            df[col].fillna(df[col].median(), inplace=True)\n",
                "    \n",
                "    # Categorical: fill with mode or 'None'\n",
                "    cat_cols = df.select_dtypes(include=['object']).columns\n",
                "    for col in cat_cols:\n",
                "        if df[col].isnull().sum() > 0:\n",
                "            mode_val = df[col].mode()\n",
                "            df[col].fillna(mode_val[0] if len(mode_val) > 0 else 'None', inplace=True)\n",
                "    \n",
                "    return df\n",
                "\n",
                "# Apply\n",
                "train_processed = handle_missing_values(train_df)\n",
                "print(f\"Missing values setelah handling: {train_processed.isnull().sum().sum()}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5.2 Feature Engineering"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "def feature_engineering(df):\n",
                "    \"\"\"Create new features\"\"\"\n",
                "    df = df.copy()\n",
                "    \n",
                "    # Total square footage\n",
                "    if all(col in df.columns for col in ['TotalBsmtSF', '1stFlrSF', '2ndFlrSF']):\n",
                "        df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
                "    \n",
                "    # Total bathrooms\n",
                "    bath_cols = ['FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath']\n",
                "    if all(col in df.columns for col in bath_cols):\n",
                "        df['TotalBath'] = df['FullBath'] + 0.5*df['HalfBath'] + df['BsmtFullBath'] + 0.5*df['BsmtHalfBath']\n",
                "    \n",
                "    # House age\n",
                "    if 'YearBuilt' in df.columns and 'YrSold' in df.columns:\n",
                "        df['HouseAge'] = df['YrSold'] - df['YearBuilt']\n",
                "    \n",
                "    # Remodel age\n",
                "    if 'YearRemodAdd' in df.columns and 'YrSold' in df.columns:\n",
                "        df['RemodAge'] = df['YrSold'] - df['YearRemodAdd']\n",
                "    \n",
                "    return df\n",
                "\n",
                "# Apply\n",
                "train_processed = feature_engineering(train_processed)\n",
                "new_features = ['TotalSF', 'TotalBath', 'HouseAge', 'RemodAge']\n",
                "print(f\"New features created: {[f for f in new_features if f in train_processed.columns]}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5.3 Encoding Kategorikal"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "def encode_categorical(df, label_encoders=None):\n",
                "    \"\"\"Encode categorical variables using LabelEncoder\"\"\"\n",
                "    df = df.copy()\n",
                "    cat_cols = df.select_dtypes(include=['object']).columns\n",
                "    \n",
                "    if label_encoders is None:\n",
                "        label_encoders = {}\n",
                "        for col in cat_cols:\n",
                "            le = LabelEncoder()\n",
                "            df[col] = le.fit_transform(df[col].astype(str))\n",
                "            label_encoders[col] = le\n",
                "    else:\n",
                "        for col in cat_cols:\n",
                "            if col in label_encoders:\n",
                "                le = label_encoders[col]\n",
                "                df[col] = df[col].astype(str).apply(\n",
                "                    lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
                "                )\n",
                "    \n",
                "    return df, label_encoders\n",
                "\n",
                "# Separate target\n",
                "y = train_processed[TARGET_COL].copy()\n",
                "X = train_processed.drop(columns=[ID_COL, TARGET_COL])\n",
                "\n",
                "# Apply encoding\n",
                "X_encoded, encoders = encode_categorical(X)\n",
                "print(f\"Shape after encoding: {X_encoded.shape}\")\n",
                "print(f\"All numeric now: {X_encoded.select_dtypes(include=['object']).shape[1] == 0}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5.4 Train/Validation Split"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Split data\n",
                "TEST_SIZE = 0.2\n",
                "RANDOM_STATE = 42\n",
                "\n",
                "X_train, X_val, y_train, y_val = train_test_split(\n",
                "    X_encoded, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
                ")\n",
                "\n",
                "print(f\"Training set: {X_train.shape}\")\n",
                "print(f\"Validation set: {X_val.shape}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5.5 Feature Scaling"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Apply StandardScaler\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = pd.DataFrame(\n",
                "    scaler.fit_transform(X_train), \n",
                "    columns=X_train.columns, \n",
                "    index=X_train.index\n",
                ")\n",
                "X_val_scaled = pd.DataFrame(\n",
                "    scaler.transform(X_val), \n",
                "    columns=X_val.columns, \n",
                "    index=X_val.index\n",
                ")\n",
                "\n",
                "print(\"Scaling applied successfully!\")\n",
                "print(f\"X_train_scaled mean: {X_train_scaled.mean().mean():.6f}\")\n",
                "print(f\"X_train_scaled std: {X_train_scaled.std().mean():.6f}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5.6 Save Preprocessed Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Save to CSV\n",
                "import os\n",
                "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
                "\n",
                "X_train_scaled.to_csv(f\"{PROCESSED_DIR}/X_train.csv\", index=False)\n",
                "X_val_scaled.to_csv(f\"{PROCESSED_DIR}/X_val.csv\", index=False)\n",
                "y_train.to_csv(f\"{PROCESSED_DIR}/y_train.csv\", index=False)\n",
                "y_val.to_csv(f\"{PROCESSED_DIR}/y_val.csv\", index=False)\n",
                "\n",
                "# Save metadata\n",
                "metadata = {\n",
                "    'feature_cols': X_train_scaled.columns.tolist(),\n",
                "    'n_train': len(X_train_scaled),\n",
                "    'n_val': len(X_val_scaled),\n",
                "    'n_features': len(X_train_scaled.columns)\n",
                "}\n",
                "\n",
                "with open(f\"{PROCESSED_DIR}/metadata.json\", 'w') as f:\n",
                "    json.dump(metadata, f, indent=2)\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"PREPROCESSING COMPLETE!\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Files saved to: {PROCESSED_DIR}/\")\n",
                "print(f\"Train samples: {metadata['n_train']}\")\n",
                "print(f\"Val samples: {metadata['n_val']}\")\n",
                "print(f\"Features: {metadata['n_features']}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "\n",
                "# **Ringkasan Preprocessing**\n",
                "\n",
                "| Step | Deskripsi | Hasil |\n",
                "|------|-----------|-------|\n",
                "| 1 | Handle Missing Values | Numeric: median, Categorical: mode |\n",
                "| 2 | Feature Engineering | 4 fitur baru (TotalSF, TotalBath, HouseAge, RemodAge) |\n",
                "| 3 | Encoding | Label Encoding untuk 43 kolom kategorikal |\n",
                "| 4 | Train/Val Split | 80/20 split (1168/292 samples) |\n",
                "| 5 | Scaling | StandardScaler (mean=0, std=1) |\n",
                "\n",
                "Dataset siap untuk tahap modelling!\n",
                "\n",
                "---"
            ],
            "metadata": {}
        }
    ]
}